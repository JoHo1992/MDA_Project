{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing a bigram and trigram model (per paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Required libraries\n",
    "\n",
    "#System\n",
    "import os\n",
    "from tqdm import tqdm \n",
    "\n",
    "#Data structure manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#text cleaning \n",
    "import re\n",
    "import string\n",
    "\n",
    "#nlp\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "\n",
    "# unlist nested lists\n",
    "import itertools\n",
    "from itertools import chain\n",
    "\n",
    "# count word frequencies\n",
    "#from collections import defaultdict\n",
    "\n",
    "# gensim\n",
    "import gensim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path to where the raw text files are stored within the session folders, i.e, converted sessions.\n",
    "origin_path = \"C:/DATA/convSes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A function for reading in the speeches\n",
    "def read_text(file_path, file):\n",
    "    \n",
    "    '''Reading the text files'''\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        doc=file.read()\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2vec.model\n"
     ]
    }
   ],
   "source": [
    "#Bringing in all the speeches\n",
    "doc_set = []\n",
    "for i in range (0,50):\n",
    "    year = 1970 + i\n",
    "    session = \"session \" + str(25+i)+ \" - \"  + str(year)\n",
    "    data_path = f\"{origin_path}\\\\{session}\"\n",
    "    os.chdir(data_path)\n",
    "    for file in os.listdir():\n",
    "        if file[-4:]=='.txt':\n",
    "            file_path = f\"{data_path}\\\\{file}\"\n",
    "            doc_set.append({'Year': year, 'ISO_Code': file[:3] , 'text': read_text(file_path, file)})\n",
    "        else:\n",
    "            print(file)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8288/8288 [00:04<00:00, 1864.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>ISO_Code</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1970</td>\n",
       "      <td>ALB</td>\n",
       "      <td>33: May I first convey to our President the co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1970</td>\n",
       "      <td>ARG</td>\n",
       "      <td>177.\\t : It is a fortunate coincidence that pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1970</td>\n",
       "      <td>AUS</td>\n",
       "      <td>100.\\t  It is a pleasure for me to extend to y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1970</td>\n",
       "      <td>AUT</td>\n",
       "      <td>155.\\t  May I begin by expressing to Ambassado...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1970</td>\n",
       "      <td>BEL</td>\n",
       "      <td>176. No doubt each of us, before coming up to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year ISO_Code                                               text\n",
       "0  1970      ALB  33: May I first convey to our President the co...\n",
       "1  1970      ARG  177.\\t : It is a fortunate coincidence that pr...\n",
       "2  1970      AUS  100.\\t  It is a pleasure for me to extend to y...\n",
       "3  1970      AUT  155.\\t  May I begin by expressing to Ambassado...\n",
       "4  1970      BEL  176. No doubt each of us, before coming up to ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns=['Year', 'ISO_Code', 'text']\n",
    "dataset = pd.concat([pd.DataFrame([i], columns=columns) for i in tqdm(doc_set)], ignore_index=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating a Subet including only G20 states**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>ISO_Code</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1970</td>\n",
       "      <td>ARG</td>\n",
       "      <td>177.\\t : It is a fortunate coincidence that pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1970</td>\n",
       "      <td>BRA</td>\n",
       "      <td>1.\\tMr. President, I should like, first of all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1970</td>\n",
       "      <td>CAN</td>\n",
       "      <td>The General Assembly is fortunate indeed to ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1970</td>\n",
       "      <td>FRA</td>\n",
       "      <td>84.\\t  Within one month, when we celebrate the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1970</td>\n",
       "      <td>GBR</td>\n",
       "      <td>110.\\t Mr. President, I should like first to s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year ISO_Code                                               text\n",
       "0  1970      ARG  177.\\t : It is a fortunate coincidence that pr...\n",
       "1  1970      BRA  1.\\tMr. President, I should like, first of all...\n",
       "2  1970      CAN  The General Assembly is fortunate indeed to ha...\n",
       "3  1970      FRA  84.\\t  Within one month, when we celebrate the...\n",
       "4  1970      GBR  110.\\t Mr. President, I should like first to s..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only select states belonging to the G20 group (minus south afrika and EU representatives)\n",
    "g20 =  dataset.ISO_Code.isin(['CAN','FRA', 'DEU', 'USA', 'GBR', 'ITA', 'JPN','ARG', 'Aus', 'BRA', 'IND', 'IDN', \n",
    "                        'CAN', 'MEX', 'RUS', 'SAU', 'KOR', 'TUR', 'CHN'])\n",
    "G20 = dataset[g20]\n",
    "\n",
    "# reset ascending index for subset dataset\n",
    "G20.reset_index(inplace = True, drop = True)\n",
    "G20.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split Speeches Into Seperate Paragraphs** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split speeches by delimiter \\n and...\n",
    "# ...stack a new row for each paragraph to dataframe... \n",
    "# ...with context info from corresponding speech.\n",
    "\n",
    "temporary_file = G20['text'].str.split('\\.\\s?\\s?\\s?\\n', expand=True).stack().reset_index(level=0)\n",
    "temporary_file.rename(columns={'level_0': 'speech_index', 0: 'text'}, inplace=True)\n",
    "# temporary_file.reset_index().drop('index',1)\n",
    "\n",
    "# merge context info from speeches with texts of paragraphs\n",
    "G20 = G20.drop('text', 1) # drop original text column\n",
    "G20 = temporary_file.merge(G20, right_index=True, left_on='speech_index', how='outer')\n",
    "\n",
    "# reorder columns in new datset\n",
    "G20['paragraph_index'] = np.arange(len(G20))\n",
    "cols = G20.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "G20 = G20[cols].set_index('paragraph_index')\n",
    "G20 = G20[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speech_index</th>\n",
       "      <th>text</th>\n",
       "      <th>Year</th>\n",
       "      <th>ISO_Code</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paragraph_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7237</th>\n",
       "      <td>145</td>\n",
       "      <td>32.\\tThis Assembly is meeting again after one ...</td>\n",
       "      <td>1979</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22826</th>\n",
       "      <td>447</td>\n",
       "      <td>The fact that South America is a region in whi...</td>\n",
       "      <td>1998</td>\n",
       "      <td>BRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23664</th>\n",
       "      <td>466</td>\n",
       "      <td>Cooperation should be strengthened on the basi...</td>\n",
       "      <td>1999</td>\n",
       "      <td>CHN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6865</th>\n",
       "      <td>137</td>\n",
       "      <td>294.\\tFunctioning indisputably as the underlyi...</td>\n",
       "      <td>1979</td>\n",
       "      <td>ARG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16873</th>\n",
       "      <td>326</td>\n",
       "      <td>When the sudden aggression of the Iraqi regime...</td>\n",
       "      <td>1990</td>\n",
       "      <td>SAU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14722</th>\n",
       "      <td>281</td>\n",
       "      <td>As part of any global strategy it is essential...</td>\n",
       "      <td>1988</td>\n",
       "      <td>ARG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10445</th>\n",
       "      <td>202</td>\n",
       "      <td>44.\\tIf the present crisis is to have a renova...</td>\n",
       "      <td>1983</td>\n",
       "      <td>BRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19632</th>\n",
       "      <td>380</td>\n",
       "      <td>United Nations action must enjoy the resolute\\...</td>\n",
       "      <td>1994</td>\n",
       "      <td>ARG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15763</th>\n",
       "      <td>302</td>\n",
       "      <td>Many developing countries do not always have s...</td>\n",
       "      <td>1989</td>\n",
       "      <td>FRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21502</th>\n",
       "      <td>417</td>\n",
       "      <td>We are contributing 312 million deutsche mark ...</td>\n",
       "      <td>1996</td>\n",
       "      <td>DEU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 speech_index  \\\n",
       "paragraph_index                 \n",
       "7237                      145   \n",
       "22826                     447   \n",
       "23664                     466   \n",
       "6865                      137   \n",
       "16873                     326   \n",
       "14722                     281   \n",
       "10445                     202   \n",
       "19632                     380   \n",
       "15763                     302   \n",
       "21502                     417   \n",
       "\n",
       "                                                              text  Year  \\\n",
       "paragraph_index                                                            \n",
       "7237             32.\\tThis Assembly is meeting again after one ...  1979   \n",
       "22826            The fact that South America is a region in whi...  1998   \n",
       "23664            Cooperation should be strengthened on the basi...  1999   \n",
       "6865             294.\\tFunctioning indisputably as the underlyi...  1979   \n",
       "16873            When the sudden aggression of the Iraqi regime...  1990   \n",
       "14722            As part of any global strategy it is essential...  1988   \n",
       "10445            44.\\tIf the present crisis is to have a renova...  1983   \n",
       "19632            United Nations action must enjoy the resolute\\...  1994   \n",
       "15763            Many developing countries do not always have s...  1989   \n",
       "21502            We are contributing 312 million deutsche mark ...  1996   \n",
       "\n",
       "                ISO_Code  \n",
       "paragraph_index           \n",
       "7237                 IND  \n",
       "22826                BRA  \n",
       "23664                CHN  \n",
       "6865                 ARG  \n",
       "16873                SAU  \n",
       "14722                ARG  \n",
       "10445                BRA  \n",
       "19632                ARG  \n",
       "15763                FRA  \n",
       "21502                DEU  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing a random sample of paragraphs\n",
    "G20.sample(10)\n",
    "# some paragraphs might be empty, this is dealth with below in the preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35103,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G20['text'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_corpus = G20['text'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')#run in conda to download the library --> python -m download en_core_web_lg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to preprocess elements for a single list, e.g. one speech or one paragraph\n",
    "def init_proc(text, stop_words=[]):\n",
    "    \n",
    "    '''Pre-processing the input in single list'''\n",
    "    \n",
    "    stops = stopwords.words(\"english\")\n",
    "    stops.extend(stop_words)\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    text = re.sub(r'\\t', ' ', text)\n",
    "    text = re.sub(r'\\-', ' ', text)\n",
    "    text = re.sub(r'\\s\\s+', ' ', text)\n",
    "    text = re.sub(r'[0-9]+','', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    lower = text.lower()\n",
    "    doc = nlp(lower)\n",
    "    words = []\n",
    "    for token in doc:\n",
    "        lemma = token.lemma_\n",
    "        if lemma not in stops:\n",
    "                words.append(lemma)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that loops the init_proc over a list, e.g. a list of speeches, or a list of paragraphs\n",
    "def pre_proc_comb(corpus,stop_words=[]):\n",
    "    \n",
    "    '''Looping the pre-processing over a list. Also checks if input is correct'''\n",
    "    \n",
    "    l = []\n",
    "    if isinstance(corpus, str):\n",
    "        l.append(init_proc(corpus,stop_words))\n",
    "    elif all(isinstance(s, str) for s in corpus):    \n",
    "        for item in tqdm(corpus):\n",
    "            l.append(init_proc(item,stop_words))\n",
    "    else:\n",
    "        print(\"Error: This function only accepts strings or a list of strings.\")\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user defined stopwords on top of nltk default stopwords\n",
    "stop_words =['general', 'assembly', 'conference', 'session', 'congratulations', \n",
    "             'congratulate', 'secretarygeneral','members', 'member', 'united', 'nations', \n",
    "             'nation', 'statement', 'honour','every', 'sir', 'majesty', 'president', \n",
    "             'minister', 'prime', 'ambassador', 'thank', 'thanks', 'world', 'international', \n",
    "             'states', 'we', 'us', 'they', 'system', 'organization','say', 'think', 'know', \n",
    "             'want', 'need', 'let', 'ask', 'go', 'look', 'stand', 'open', 'give', 'see', 'come', \n",
    "             'make', 'made', 'meet','act', 'use', 'take', 'bring', 'ensure', 'able', 'assume', \n",
    "             'continue', 'change', 'progress', 'process', 'year', 'years', 'time', 'today',  \n",
    "             'would', 'will', 'might', 'together', 'common', 'future', 'one', 'order', 'end', \n",
    "             'new', 'necessary', 'major', 'minor', 'many', 'people', 'peoples', 'appropriate', \n",
    "             'historic', 'adequate', 'best', 'better', 'confident', 'important', 'special',\n",
    "             'great', 'therefore', 'thus', 'hence', 'like', 'particularly', 'many', 'much', \n",
    "             'greater', 'especially', 'towards', 'always', 'whether', 'around',\n",
    "             'possible', 'clear', 'simply', 'must', 'also', 'however', 'mr',\n",
    "             'united', 'kingdom', 'great', 'britain', 'france', 'germany','italy', 'japan',\n",
    "             'canada', 'usa', 'argentina', 'australia', 'china', 'brazil', 'india', 'indonesia',  \n",
    "             'mexico', 'russia', 'saudi', 'arabia', 'south', 'korea', 'turkey','liechtenstein',\n",
    "             'I', ' ', '  ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing the whole corpus of speeches (per paragraph) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35103/35103 [09:55<00:00, 58.93it/s]\n"
     ]
    }
   ],
   "source": [
    "processed_corpus = pre_proc_comb(text_corpus, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_phrases = gensim.models.Phrases(processed_corpus,\n",
    "                                       min_count = 5,#Ignore all words and bigrams with total collected count lower than this value\n",
    "                                       threshold = 100)#The minimum score for a bigram to be taken into account.\n",
    "trigram_phrases = gensim.models.Phrases(bigram_phrases[processed_corpus],threshold = 100)\n",
    "bigram = gensim.models.phrases.Phraser = (bigram_phrases)\n",
    "trigram = gensim.models.phrases.Phraser = (trigram_phrases)\n",
    "\n",
    "bigram.save(\"C:/DATA/DTM/phrasers/bigram_paragraphs\")\n",
    "trigram.save(\"C:/DATA/DTM/phrasers/trigram_paragraphs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
